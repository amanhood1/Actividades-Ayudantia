---
title: "Actividad Ayudantia 9"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Actividad

Para la actividad de esta ayudantía tendrá que utilizar dos datasets, el primer dataset que utilizar para la regresión lineal será la data de los autos usados del fabricante toyota. El segundo dataset para la regresión logística será el dataset de los vinos que hemos utilizado antes, donde se busca clasificar según la calidad del vino. (Entrega límite: 6/06/2021 23:59)

## Cargar Librerias 

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(GGally)
library(regclass)
library(pROC)
library(rsample)
```

## Cargar Datos

```{r}
setwd("C:/Users/amanh/OneDrive/Documentos/GitHub/Actividades-Ayudantia/Actividad9")
toyota <- read.csv("toyota.csv", sep = ",")
wine <- read.csv("winequality-red.csv", sep = ",")
```

# Limpieza de datos

## Búsqueda de datos faltantes

```{r}
summary(toyota)
```

Al aplicar la función "summary" podemos corroborar que ninguna base de datos tiene valores faltantes, por ende, se procede con la actividad.

# Regresion Lineal con database Toyota

Lo que buscamos en esta primera actividad, es predecir el precio al que venderíamos nuestro auto en caso de que este fuese un Toyota. 

Para esto transformamos las variables del modelo, transmision y tipo de combustible, a factores para trabajar con dichos valores como "etiquetas"

```{r}
toyota$model <- as.factor(toyota$model)
toyota$transmission <- as.factor(toyota$transmission)
toyota$fuelType <- as.factor(toyota$fuelType)
summary(toyota)
```

Podemos ver que un valor en el tamaño del motor de 0 no tiene mucho sentido por lo que revisaremos cuantas observaciones presentan este este valor, y en caso de haber datos con valor 0 los eliminamos de nuestro dataset

```{r}
toyota %>% filter(engineSize == 0) %>% nrow()
toyota <- toyota %>%  filter(engineSize != 0)
summary(toyota)
```

Una vez ya listo nuestro datos, realizamos una visualizacion de nuestro datos numericos, para ver la correlacion que pueda existir entre las variables y la distribucion de los datos. 

```{r, message=FALSE, warning=FALSE}
toyota %>% select(year, mileage, tax, mpg, engineSize, price) %>% 
  ggpairs(lower = list(continuous = wrap("points", alpha = 0.3, size = 0.5)))
```

Lo que nos interesa ahora es elegir aquellas variables que presenten una alta correlación con el precio (da lo mismo el signo de esta) para de esta manera entregar una predicción lo más certera 

Revisamos como se distribuyen los datos que pasamos a factor en relacion al precio, para esto utilizamos los boxplot lo que tambien nos ayudara a ver si existen valores atipicos que puedan alterar nuestro modelo.

```{r}
toyota %>% ggplot(aes(transmission, price)) +geom_boxplot()
toyota %>% ggplot(aes(fuelType, price)) + geom_boxplot()
toyota %>% mutate(model = reorder(model, price)) %>% ggplot(aes(price, model)) + geom_boxplot()
```

Podemos ver que hay diversos datos atípicos, todo esto por medio de inspección visual.

Graficamos las cuatro variables con mayores valores, para ver como se distribuyen de acuerdo al precio. 

```{r}
toyota %>% ggplot(aes(mileage, price)) +
  geom_point(alpha = .1) +
  stat_smooth(method = "gam", formula = y ~ s(x, k=3))
toyota %>% ggplot(aes(year, price)) +
  geom_point(alpha = .1) +
  stat_smooth(method = "gam", formula = y ~ s(x, k=3))
toyota %>% ggplot(aes(mpg, price)) +
  geom_point(alpha = .1) +
  stat_smooth(method = "gam", formula = y ~ s(x, k=3))
toyota %>% ggplot(aes(engineSize, price)) +
  geom_point(alpha = .1) +
  stat_smooth(method = "gam", formula = y ~ s(x, k=3))
toyota %>% filter(., year >= 2005) %>% ggplot(aes(year, price)) +
  geom_point(alpha = .1) +
  stat_smooth(method = "gam", formula = y ~ s(x, k=3))
```

Escalamos los datos antes de ralizar el analisis de regresion

```{r}
toyota_sca <- toyota
toyota_sca[,c(2,3,5,7,8,9)] <- scale(toyota_sca[,c(2,3,5,7,8,9)])
toyota_sca %>%  head()
```

## Regresion simple: tamaño motor para predecir precio 

```{r}
reg_simp <- lm(price ~ engineSize, data = toyota)
summary(reg_simp)
```

Solo se explica el 53% del modelo. Los resultados de la regresion nos indican que los valores de los parametros son -3202.6 para el intercepto y 10679.5 para el coeficiente asociado a la variable del tamaño del motor.

## Regresion multiple con el tamaño del motor y el año  para predecir el precio 

```{r}
reg_mult <- lm(price ~ engineSize + year*mileage, data = toyota_sca)
summary(reg_mult)
```

Se aprecia un mejor rendimiento, al incluir una nueva variable. El modelo dado como resultado, que ahora se explica un 76,8% de la varianza. Ademas, todas las variables resultan ser significativas para el modelo.

## VIF

Revisamos el valor del factor de inflacion de la varianza, este factor nos permite entender la colinealidad de los datos. Un VIF por encima de 4 o una tolerancia por debajo de 0,25 indica que podría existir multicolinealidad y se requiere más investigación.

```{r}
VIF(reg_mult)
```

Los valores referentes al estudio del VIF no presentan multicolinealidad, ya que son menores a 0,25. Por ende, se concluye este modelo.

# Regresion Logistica con data de Vinos

Lo que buscamos en esta segunda actividad, es predecir calidad del vino a partir de características propias de este producto.

## Búsqueda de datos faltantes

```{r}
summary(wine)
```

Al aplicar la función "summary" podemos corroborar que ninguna base de datos tiene valores faltantes, por ende, se procede con la actividad.

## Visualización de la data

De comienzo, al realizar inspección visual sobre la base de datos de vinos, apreicamos que hay una variable llamada "quality". Por ende, procedemos con graficar esta para ver de que manera se comporta.

```{r}
glimpse(wine)
attach(wine)
ggplot(wine,aes(x=factor(quality))) +
  geom_bar(col ="black",fill="#993333",alpha=0.5) +
  theme(axis.text.x = element_text(face="bold", size=10)) +
  scale_x_discrete("Calidad") +
  scale_y_continuous("Count")
```

Podemos ver que existen muchos vinos con una calidad "promedio", hasta cierto punto que distribuyen "normal", pero no es tan así. De todas maneras se procedera ahora con hacer el análisis de aquellas variables que le dan la calidad que tiene a cada vino.

## Fallo al realizar el análisis según ayudantía

{r}
set.seed(369)
summary(wine)
glm.fit <- glm(quality_01 ~ pH, data = wine , family = "binomial")
summary(glm.fit)

Al hacer funcionar esta línea en un chunk, nos percatamos que para hacer funcionar este código es necesario tener una variable para poder separar de acuerdo a un rango la calidad. Ya que el modelo requiere que sean varibles en 0 y 1. Esto fue visto en ayudantía, por ende se procede a realizar una conversión. 

## Falla arreglada para seguir con el análisis

## Segmentar variable Quality

Para esto se tomara la mitad del intervalo entre nota minima y maxima. De esta manera podremos generar la variable necesaria para el analisis.

```{r}
summary(wine)
for(i in 1:dim(wine)){
  if (quality[i]>= 5.5)
     wine$quality_01[i]=1
  if (quality[i]< 5.5)
    wine$quality_01[i]=0
}
attach(wine)
```

## Regresión Logistica Simple: predecir Calidad por el pH

Decido utilizar esta varible, ya que creo que a partir del pH de un vino, es posible de alguna manera determinar, o dar luces respecto de su calidad.

```{r}
set.seed(369)
summary(wine)
glm.fit <- glm(quality_01 ~ pH, data = wine , family = "binomial")
summary(glm.fit)
```

## Curva ROC
```{r}
prob <- predict(glm.fit, type = c("response"))
wine$prob <- prob
curva_roc <- roc(quality_01 ~ prob, data = wine)
plot(curva_roc)
auc(curva_roc)
```

La curva ROC muestra un valor de 50%, lo cual indica una explicación que deja bastante desear, ya que nos interesaría que este valor estuviese cercano a algo como 70%

## Regresión Logistica Multiple para predecir Calidad desde todas las variables restantes

Para mejorar, o intentarlo, utilizaremos el resto de variables presentes en la base de datos.

```{r}
wine$prob <- NULL
modelo_log_multi <- glm(quality_01 ~ alcohol + sulphates  + pH + density + total.sulfur.dioxide + free.sulfur.dioxide + chlorides + residual.sugar + citric.acid + volatile.acidity, wine, family = "binomial")
summary(modelo_log_multi)
```

```{r}
prob_multi <- predict(modelo_log_multi, type = c("response"))
wine$prob_multi <- prob_multi
curva_roc_multi <- roc(quality_01 ~ prob_multi, data = wine)
plot(curva_roc_multi)
auc(curva_roc_multi)
```

Vemos una mejora iimportante, ya que el modelo se explica en un 82%.

## Ocupando Modelos de Entrenamiento

```{r}
set.seed(369)
data_split <- initial_split(wine,prop = 0.7,strata = NULL)
train_data <- training(data_split) %>% as.data.frame() 
test_data <- testing(data_split) %>%  as.data.frame()
modelo_log_multi1 <- glm(quality_01 ~ alcohol + sulphates  + pH + density + total.sulfur.dioxide + free.sulfur.dioxide + chlorides + residual.sugar + citric.acid + volatile.acidity, wine, family = "binomial")
summary(modelo_log_multi1)
```

```{r}
test_data$prob_multi <- predict(modelo_log_multi1, test_data, type = c("response"))
auc(roc(quality_01 ~ prob_multi, data = test_data))
```

La predicción mejora dado que el modelo se explica en un 85%, lo cual es mejor que lo anterior.